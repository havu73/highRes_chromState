{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e072c57-baf5-4519-9417-9c7b4dc9af9b",
   "metadata": {},
   "source": [
    "# A first attempt at generating some data\n",
    "\n",
    "Based on this model. Some notation\n",
    "\n",
    "M: # regions  \n",
    "N: # of bins per region  \n",
    "L: # of signals  \n",
    "\n",
    "alpha: params of dirichlet prior over reference epigenomes  \n",
    "beta: ref->sample state categorical distribution  \n",
    "p: state->signal bernoulli distribution\n",
    "r: reference state at each region/bin\n",
    "pi: the mixture probabilities of reference epigenome\n",
    "\n",
    "```\n",
    "for each region d do\n",
    "  draw ref distr pi_d ~ Dir(alpha)\n",
    "  for each genomic position i in d do\n",
    "    sample ref z_di ~ Categorical(p_d)\n",
    "    sample state s_di ~ Categorical(beta_{r_{z_{di}}})\n",
    "    for each signal j do\n",
    "      sample m_{dij} ~ Bernoulli(p_{s_{di}})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e11c38e8-d037-4787-adb1-c94414666756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some parameters\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d9ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 1.],\n",
      "        [1., 0., 2.],\n",
      "        [2., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# this is sample code for the case where we want varied state patterns from each reference\n",
    "# and that there are actually groups of references that are similar to each other\n",
    "num_references = 9\n",
    "num_groups = 3\n",
    "num_ref_per_groups = np.ceil(num_references/num_groups).astype(int)\n",
    "num_states = 3\n",
    "num_signals = 3\n",
    "num_bins = 100\n",
    "sample_r = torch.zeros(num_states, num_groups)\n",
    "for i in range(num_groups):\n",
    "    sample_r[:,i] = torch.arange(num_states).roll(i)\n",
    "print(sample_r)\n",
    "sample_r = sample_r.repeat(np.ceil(num_bins / num_states).astype(int), 1)\n",
    "sample_r.shape\n",
    "r = torch.zeros(sample_r.shape[0], num_references)\n",
    "for i in range(num_references):\n",
    "    r[:,i] = sample_r[:, i%num_groups]\n",
    "\n",
    "change_rate = 0.01 # 1% chance of differences across references from the same group across the genome\n",
    "num_change = int(change_rate * num_bins)\n",
    "\n",
    "for i in [3]: #range(num_states, num_references): # for the first num_states columns, keep all the state assignments\n",
    "    org_r = r[:,i]\n",
    "    indices_to_change = np.random.choice(num_bins, num_change)\n",
    "    indices_to_change = torch.tensor(indices_to_change).type(torch.LongTensor)\n",
    "    states_to_change = torch.tensor(np.random.choice(num_states, num_change)).float()\n",
    "    r[indices_to_change,i] = states_to_change\n",
    "\n",
    "r = r[:num_bins, :num_references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32767953-fb13-4a80-84de-22ddce554dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:\n",
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "beta:\n",
      "tensor([[0.8333, 0.0833, 0.0833],\n",
      "        [0.0833, 0.8333, 0.0833],\n",
      "        [0.0833, 0.0833, 0.8333]])\n"
     ]
    }
   ],
   "source": [
    "alpha = torch.from_numpy(np.arange(num_references) + 1).float()\n",
    "beta = torch.zeros((num_states, num_states))\n",
    "for i in range(num_states):\n",
    "    w = torch.ones(num_states)\n",
    "    w[i] = 10\n",
    "    beta[i,:] = w / torch.sum(w)\n",
    "\n",
    "print('alpha:')\n",
    "print(alpha)\n",
    "\n",
    "print('beta:')\n",
    "    print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3612bc-4e2f-4a80-8188-1c6b96ae7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "tensor([[0.8333, 0.0833, 0.0833],\n",
      "        [0.0833, 0.8333, 0.0833],\n",
      "        [0.0833, 0.0833, 0.8333],\n",
      "        [0.8333, 0.0833, 0.0833],\n",
      "        [0.0833, 0.8333, 0.0833]])\n"
     ]
    }
   ],
   "source": [
    "p = torch.zeros((num_states, num_signals)) # 2d, bernoulli params for p(signals|states)\n",
    "for i in range(num_states):\n",
    "    w = torch.ones(num_signals)\n",
    "    w[i % num_signals] = 10\n",
    "    p[i,:] = w / torch.sum(w)\n",
    "\n",
    "print('p')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0200ef-0ef6-4503-9b8a-628d404414c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 5, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_states = torch.zeros((num_regions, num_bins_per_region, num_references))\n",
    "for i in range(num_references):\n",
    "    ref_states[:,:,i] = i % num_states\n",
    "ref_states.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0247ca7d-bd56-4cad-a295-ff1dec0276bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 5, 10, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_states_indicator = torch.zeros((num_regions, num_bins_per_region, num_references, num_states))\n",
    "for i in range(num_regions):\n",
    "    for j in range(num_bins_per_region):\n",
    "        for k in range(num_references):\n",
    "            ref_states_indicator[i, j, k, ref_states[i,j,k].long()] = 1.\n",
    "print(ref_states_indicator.shape)\n",
    "ref_states_indicator[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93157806-4f8d-4ded-8546-b2bb5d52c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "tensor([0.0255, 0.0367, 0.0235, 0.0454, 0.0598, 0.1338, 0.0773, 0.0793, 0.2873,\n",
      "        0.2314])\n",
      "tensor([0.1594, 0.1140, 0.1028, 0.3327, 0.2911])\n"
     ]
    }
   ],
   "source": [
    "# this piece of code is just to debug, not relevant to what gets generated in the ToyGenerator class\n",
    "pi = dist.Dirichlet(alpha).sample()\n",
    "collapsed_pi = torch.matmul(ref_states_indicator[i,j,:,:].T, pi) # just the prob of states at the last genomic pos\n",
    "assert torch.sum(collapsed_pi) == 1\n",
    "print(alpha)\n",
    "print(pi)\n",
    "print(collapsed_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa04b9c-7c51-44f9-a94e-b637ad002b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ToyGenerator:\n",
    "    def __init__(self,  \n",
    "                 num_bins=5, \n",
    "                 num_references=10, \n",
    "                 num_signals=3,\n",
    "                 num_states=5,\n",
    "                 high_w=100):\n",
    "        self.num_bins = num_bins\n",
    "        self.num_references = num_references\n",
    "        self.num_signals = num_signals\n",
    "        self.num_states = num_states\n",
    "        self.high_w = high_w\n",
    "        self.sample = None\n",
    "        self.params = self.set_params()\n",
    "    \n",
    "        \n",
    "    # parameter of state->signal distributions\n",
    "    # shape is (num_states, num_signals)\n",
    "    def generate_param_p(self):\n",
    "        p = torch.zeros((self.num_states, self.num_signals))\n",
    "        for i in range(self.num_states):\n",
    "            w = -self.high_w * torch.ones(self.num_signals)\n",
    "            w[i % self.num_signals] = self.high_w\n",
    "            p[i,:] = w\n",
    "        return p\n",
    "    \n",
    "    # generate a state assignment tensor\n",
    "    # shape is (num_regions, num_bins_per_region, num_references)\n",
    "    def generate_ref_states(self):\n",
    "        ref_states = torch.zeros(\n",
    "            (self.num_bins, \n",
    "             self.num_references))\n",
    "        \n",
    "        for i in range(self.num_references):\n",
    "            ref_states[:,i] = i % self.num_states\n",
    "        return ref_states.long()\n",
    "    \n",
    "    # set parameters of the data generator\n",
    "    def set_params(self):\n",
    "        # parameters of the dirichlet over references\n",
    "        # same one for every region\n",
    "        # very high probability that generated sample looks like\n",
    "        # reference 0\n",
    "        # shape is (num_references,)\n",
    "        alpha = torch.ones(self.num_references)\n",
    "        alpha[0] = self.high_w\n",
    "        \n",
    "        # parameters of bernoulli distribution for each signal\n",
    "        # for each state\n",
    "        # shape is (num_states, num_signals)\n",
    "        p = self.generate_param_p()\n",
    "        \n",
    "        # an indicator matrix along genome of the state for \n",
    "        # each refenrece\n",
    "        # shape is (num_regions, num_bins_per_region, num_states, num_references)\n",
    "        ref_states_indicator = F.one_hot(self.generate_ref_states(), self.num_states)\n",
    "        params = {\n",
    "            'alpha': alpha,\n",
    "            'p': p,\n",
    "            'ref_states_indicator': ref_states_indicator\n",
    "        }\n",
    "        self.params = params\n",
    "        return params\n",
    "        \n",
    "    # collapse a prob vector over references to a prob vector over states\n",
    "    # takes the cross product of prob vector pi and reference state indicator matrix r\n",
    "    # shapes:\n",
    "    #  pi: (None, num_references)\n",
    "    #  r: (None, num_references, num_states)\n",
    "    #  out: (None, num_states)\n",
    "    def collapse_pi(self, pi, r=None):\n",
    "        if r is None:\n",
    "            assert self.params is not None\n",
    "            r = self.params['ref_states_indicator']\n",
    "            \n",
    "        r = r.float()\n",
    "        collapsed_pi = torch.zeros(pi.shape[0], r.shape[2])\n",
    "        for i in range(pi.shape[0]):\n",
    "            collapsed_pi[i,:] = torch.matmul(r[i,:,:].T, pi[i,:])\n",
    "        return collapsed_pi\n",
    "    \n",
    "    def generate_sample(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "            \n",
    "        r = self.params['ref_states_indicator']\n",
    "                \n",
    "        # generate reference distribution for each region\n",
    "        with pyro.plate('bins', self.num_bins):\n",
    "            # pi is shape (num_regions, num_references)\n",
    "            pi = pyro.sample('pi', dist.Dirichlet(self.params['alpha']))\n",
    "            # collapse the reference distribution for each bin to a \n",
    "            # state distribution \n",
    "            collapsed_pi = self.collapse_pi(pi, r)\n",
    "\n",
    "            signal_params = torch.sigmoid(torch.matmul(collapsed_pi, self.params['p']))\n",
    "            m = pyro.sample('m', dist.Bernoulli(signal_params).to_event(1))\n",
    "\n",
    "        result = {\n",
    "            'pi': pi,\n",
    "            'm': m\n",
    "        }\n",
    "        self.sample = result\n",
    "        return self.sample\n",
    "    \n",
    "    def get_sampled_collapsed_theta(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        theta = self.sample['theta']\n",
    "        return self.collapse_theta(theta)\n",
    "    \n",
    "    def get_sampled_collapsed_pi(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        pi = self.sample['pi']\n",
    "        return self.collapse_pi(pi)\n",
    "    \n",
    "    def get_sampled_signals(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['m']\n",
    "    \n",
    "    def get_sampled_pi(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['pi']\n",
    "    \n",
    "    def get_signal_parms(self):\n",
    "        collapsed_pi = self.get_sampled_collapsed_pi()\n",
    "        return torch.sigmoid(torch.matmul(collapsed_pi, self.params['p']))\n",
    "    \n",
    "    def get_ref_state_indicators(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "        return self.params['ref_states_indicator']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7303aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CircularStateGenerator:\n",
    "    # Within the number of references, there is a group of references that will be similar to the \n",
    "    # sample of interests in terms of state assignments\n",
    "    def __init__(self,  \n",
    "                 num_bins=5, \n",
    "                 num_references=10, \n",
    "                 num_groups=3,\n",
    "                 state_vary_rate=0.01, \n",
    "                 # fraction of the genome where the state assignments among references of the same group are diff\n",
    "                 num_signals=3,\n",
    "                 num_states=5,\n",
    "                 high_w=100):\n",
    "        self.num_bins = num_bins\n",
    "        self.num_references = num_references\n",
    "        self.num_groups = num_groups\n",
    "        self.state_vary_rate = state_vary_rate\n",
    "        self.num_signals = num_signals\n",
    "        self.num_states = num_states\n",
    "        self.high_w = high_w\n",
    "        self.sample = None\n",
    "        self.params = self.set_params()\n",
    "    \n",
    "        \n",
    "    # parameter of state->signal distributions\n",
    "    # shape is (num_states, num_signals)\n",
    "    def generate_param_p(self):\n",
    "        p = torch.zeros((self.num_states, self.num_signals))\n",
    "        for i in range(self.num_states):\n",
    "            w = -self.high_w * torch.ones(self.num_signals)\n",
    "            w[i % self.num_signals] = self.high_w\n",
    "            p[i,:] = w\n",
    "        return p\n",
    "    \n",
    "    # generate a state assignment tensor\n",
    "    # shape is (num_regions, num_bins_per_region, num_references)\n",
    "    def generate_ref_states(self):\n",
    "        # this is code for the case where we want varied state patterns from each reference\n",
    "        # and that there are actually groups of references that are similar to each other\n",
    "        num_ref_per_groups = np.ceil(self.num_references/self.num_groups).astype(int)\n",
    "        sample_r = torch.zeros(self.num_states, self.num_groups)\n",
    "        for i in range(self.num_groups):\n",
    "            sample_r[:,i] = torch.arange(self.num_states).roll(i)\n",
    "            # each group has a circular permutation of states that are characteristics to that group\n",
    "        sample_r = sample_r.repeat(np.ceil(self.num_bins / self.num_states).astype(int), 1)\n",
    "        # now r is just a repeated sequence of sample_r\n",
    "        r = torch.zeros(sample_r.shape[0], self.num_references)\n",
    "        for i in range(self.num_references):\n",
    "            r[:,i] = sample_r[:, i % self.num_groups]\n",
    "        # now we will start to introduce some random changes to the state assignments among references from\n",
    "        # the same groups\n",
    "        num_change = int(self.change_rate * self.num_bins)\n",
    "        for i in range(self.num_states, self.num_references): \n",
    "            # for the first num_states columns, keep all the state assignments\n",
    "            # if num_references < num_states, this loop will not be called\n",
    "            org_r = r[:,i]\n",
    "            indices_to_change = np.random.choice(self.num_bins, num_change)\n",
    "            indices_to_change = torch.tensor(indices_to_change).type(torch.LongTensor)\n",
    "            states_to_change = torch.tensor(np.random.choice(self.num_states, num_change)).float()\n",
    "            r[indices_to_change,i] = states_to_change\n",
    "        return r.long() # num_bins, num_references --> values: state-0-based \n",
    "    \n",
    "    # set parameters of the data generator\n",
    "    def set_params(self):\n",
    "        # parameters of the dirichlet over references\n",
    "        # same one for every region\n",
    "        # very high probability that generated sample looks like\n",
    "        # reference 0\n",
    "        # shape is (num_references,)\n",
    "        alpha = torch.ones(self.num_references)\n",
    "        num_ref_per_groups = np.ceil(self.num_references/self.num_groups).astype(int)\n",
    "        for i in range(self.num_references):\n",
    "            if i % self.num_groups == 0:\n",
    "                alpha[i] = self.high_w # all refs in group 1 will be more similar to sample of interest\n",
    "        \n",
    "        # parameters of bernoulli distribution for each signal\n",
    "        # for each state\n",
    "        # shape is (num_states, num_signals)\n",
    "        p = self.generate_param_p()\n",
    "        \n",
    "        # an indicator matrix along genome of the state for \n",
    "        # each refenrece\n",
    "        # shape is (num_regions, num_bins_per_region, num_states, num_references)\n",
    "        ref_states_indicator = F.one_hot(self.generate_ref_states(), self.num_states)\n",
    "        params = {\n",
    "            'alpha': alpha,\n",
    "            'p': p,\n",
    "            'ref_states_indicator': ref_states_indicator\n",
    "        }\n",
    "        self.params = params\n",
    "        return params\n",
    "        \n",
    "    # collapse a prob vector over references to a prob vector over states\n",
    "    # takes the cross product of prob vector pi and reference state indicator matrix r\n",
    "    # shapes:\n",
    "    #  pi: (None, num_references)\n",
    "    #  r: (None, num_references, num_states)\n",
    "    #  out: (None, num_states)\n",
    "    def collapse_pi(self, pi, r=None):\n",
    "        if r is None:\n",
    "            assert self.params is not None\n",
    "            r = self.params['ref_states_indicator']\n",
    "            \n",
    "        r = r.float()\n",
    "        collapsed_pi = torch.zeros(pi.shape[0], r.shape[2])\n",
    "        for i in range(pi.shape[0]):\n",
    "            collapsed_pi[i,:] = torch.matmul(r[i,:,:].T, pi[i,:])\n",
    "        return collapsed_pi\n",
    "    \n",
    "    def generate_sample(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "            \n",
    "        r = self.params['ref_states_indicator']\n",
    "                \n",
    "        # generate reference distribution for each region\n",
    "        with pyro.plate('bins', self.num_bins):\n",
    "            # pi is shape (num_regions, num_references)\n",
    "            pi = pyro.sample('pi', dist.Dirichlet(self.params['alpha']))\n",
    "            # collapse the reference distribution for each bin to a \n",
    "            # state distribution \n",
    "            collapsed_pi = self.collapse_pi(pi, r)\n",
    "\n",
    "            signal_params = torch.sigmoid(torch.matmul(collapsed_pi, self.params['p']))\n",
    "            m = pyro.sample('m', dist.Bernoulli(signal_params).to_event(1))\n",
    "\n",
    "        result = {\n",
    "            'pi': pi,\n",
    "            'm': m\n",
    "        }\n",
    "        self.sample = result\n",
    "        return self.sample\n",
    "    \n",
    "    def get_sampled_collapsed_theta(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        theta = self.sample['theta']\n",
    "        return self.collapse_theta(theta)\n",
    "    \n",
    "    def get_sampled_collapsed_pi(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        pi = self.sample['pi']\n",
    "        return self.collapse_pi(pi)\n",
    "    \n",
    "    def get_sampled_signals(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['m']\n",
    "    \n",
    "    def get_sampled_pi(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['pi']\n",
    "    \n",
    "    def get_signal_parms(self):\n",
    "        collapsed_pi = self.get_sampled_collapsed_pi()\n",
    "        return torch.sigmoid(torch.matmul(collapsed_pi, self.params['p']))\n",
    "    \n",
    "    def get_ref_state_indicators(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "        return self.params['ref_states_indicator']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be54fe20-b402-44be-a039-381c45041145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "generator = ToyGenerator(**toy_parms, high_w=1000)\n",
    "m = generator.get_sampled_signals()\n",
    "r = generator.get_ref_state_indicators()\n",
    "collapsed_p = generator.get_sampled_collapsed_pi()\n",
    "pi = generator.get_sampled_pi()\n",
    "signal_params = generator.get_signal_parms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460919d9-4f32-479a-8a4b-1f2c08e84357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_bins': 25, 'num_references': 10, 'num_signals': 3, 'num_states': 4}\n",
      "m\n",
      "torch.Size([25, 3])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.],\n",
      "        [1., 0., 0.]])\n",
      "r\n",
      "torch.Size([25, 10, 4])\n",
      "collapsed_p\n",
      "torch.Size([25, 4])\n",
      "tensor([[9.8977e-01, 8.0981e-03, 8.0478e-04, 1.3236e-03],\n",
      "        [9.9428e-01, 3.9146e-03, 1.1215e-03, 6.8044e-04],\n",
      "        [9.9168e-01, 5.9865e-03, 8.6178e-04, 1.4704e-03],\n",
      "        [9.9291e-01, 3.8557e-03, 1.5624e-03, 1.6745e-03],\n",
      "        [9.9717e-01, 1.3651e-03, 8.1109e-04, 6.5001e-04],\n",
      "        [9.8668e-01, 4.6588e-04, 9.8724e-03, 2.9795e-03],\n",
      "        [9.9184e-01, 3.4085e-03, 7.8606e-04, 3.9656e-03],\n",
      "        [9.9557e-01, 1.4311e-03, 1.8135e-03, 1.1860e-03],\n",
      "        [9.9350e-01, 1.3147e-03, 3.5633e-03, 1.6213e-03],\n",
      "        [9.9443e-01, 1.8613e-03, 2.1614e-03, 1.5492e-03],\n",
      "        [9.8968e-01, 2.4032e-03, 4.2711e-03, 3.6456e-03],\n",
      "        [9.9331e-01, 3.4854e-03, 2.7755e-03, 4.3053e-04],\n",
      "        [9.9072e-01, 3.7037e-03, 3.6014e-03, 1.9704e-03],\n",
      "        [9.9164e-01, 1.7322e-03, 1.4781e-03, 5.1504e-03],\n",
      "        [9.8878e-01, 6.8711e-03, 1.1100e-03, 3.2366e-03],\n",
      "        [9.9364e-01, 1.9056e-03, 3.9578e-03, 4.9447e-04],\n",
      "        [9.9491e-01, 1.4233e-03, 1.4267e-03, 2.2439e-03],\n",
      "        [9.9470e-01, 2.1287e-03, 7.8914e-04, 2.3857e-03],\n",
      "        [9.9197e-01, 2.0246e-03, 5.2247e-03, 7.7975e-04],\n",
      "        [9.9429e-01, 3.7135e-03, 1.0577e-03, 9.4085e-04],\n",
      "        [9.9555e-01, 2.0541e-03, 1.2768e-03, 1.1183e-03],\n",
      "        [9.9417e-01, 2.0436e-03, 9.8086e-04, 2.8090e-03],\n",
      "        [9.9534e-01, 3.2538e-03, 1.3338e-04, 1.2702e-03],\n",
      "        [9.9584e-01, 2.1256e-03, 1.4198e-03, 6.1488e-04],\n",
      "        [9.9194e-01, 2.1943e-03, 1.8144e-03, 4.0490e-03]])\n",
      "pi\n",
      "torch.Size([25, 10])\n",
      "tensor([[9.8746e-01, 6.5131e-04, 5.9653e-04, 1.3090e-05, 1.4159e-03, 5.1590e-03,\n",
      "         2.0825e-04, 1.3105e-03, 9.0076e-04, 2.2878e-03],\n",
      "        [9.9373e-01, 2.2466e-03, 1.1176e-03, 3.6792e-04, 4.3453e-04, 1.0988e-03,\n",
      "         3.9621e-06, 3.1252e-04, 1.1472e-04, 5.6918e-04],\n",
      "        [9.8579e-01, 2.7369e-05, 5.8784e-04, 8.3623e-04, 5.3143e-03, 3.9741e-03,\n",
      "         2.7395e-04, 6.3421e-04, 5.7753e-04, 1.9851e-03],\n",
      "        [9.9195e-01, 1.2581e-03, 1.0064e-03, 5.3790e-04, 8.1071e-04, 2.3722e-04,\n",
      "         5.5594e-04, 1.1366e-03, 1.4958e-04, 2.3604e-03],\n",
      "        [9.9235e-01, 5.7480e-04, 6.5596e-04, 2.0456e-04, 9.1878e-05, 5.9615e-05,\n",
      "         1.5513e-04, 4.4545e-04, 4.7282e-03, 7.3073e-04],\n",
      "        [9.8512e-01, 9.5860e-05, 7.2554e-03, 1.4922e-03, 1.3073e-04, 1.6792e-04,\n",
      "         2.6169e-03, 1.4873e-03, 1.4323e-03, 2.0211e-04],\n",
      "        [9.8729e-01, 1.0571e-03, 4.7656e-04, 3.6751e-03, 1.0543e-03, 1.0529e-03,\n",
      "         3.0950e-04, 2.9053e-04, 3.4967e-03, 1.2985e-03],\n",
      "        [9.9189e-01, 3.7422e-04, 1.3628e-03, 1.1601e-03, 1.4441e-03, 2.1680e-04,\n",
      "         4.5063e-04, 2.5906e-05, 2.2308e-03, 8.4013e-04],\n",
      "        [9.9233e-01, 8.4696e-05, 1.9969e-03, 1.9123e-04, 3.5659e-04, 9.7438e-05,\n",
      "         1.5665e-03, 1.4301e-03, 8.1131e-04, 1.1326e-03],\n",
      "        [9.8978e-01, 2.9123e-05, 4.2682e-04, 5.1644e-04, 4.3369e-03, 1.2497e-03,\n",
      "         1.7346e-03, 1.0328e-03, 3.1084e-04, 5.8250e-04],\n",
      "        [9.8865e-01, 8.3722e-04, 4.0287e-03, 9.3261e-04, 1.4177e-04, 6.0488e-04,\n",
      "         2.4237e-04, 2.7130e-03, 8.9178e-04, 9.6115e-04],\n",
      "        [9.8928e-01, 2.8233e-04, 1.1512e-03, 3.8033e-04, 2.6058e-03, 1.4710e-03,\n",
      "         1.6243e-03, 5.0207e-05, 1.4240e-03, 1.7320e-03],\n",
      "        [9.8681e-01, 1.6189e-03, 2.0956e-03, 7.5563e-04, 2.5140e-03, 1.3822e-03,\n",
      "         1.5058e-03, 1.2148e-03, 1.3974e-03, 7.0256e-04],\n",
      "        [9.9088e-01, 7.5439e-05, 1.1850e-03, 4.5442e-03, 6.4471e-05, 1.0497e-03,\n",
      "         2.9315e-04, 6.0621e-04, 6.8985e-04, 6.0706e-04],\n",
      "        [9.8645e-01, 6.4522e-04, 4.4120e-04, 1.5945e-03, 1.7538e-04, 4.7270e-04,\n",
      "         6.6876e-04, 1.6421e-03, 2.1539e-03, 5.7531e-03],\n",
      "        [9.9343e-01, 9.8188e-05, 2.0779e-03, 4.2339e-04, 1.1690e-04, 1.2928e-03,\n",
      "         1.8799e-03, 7.1079e-05, 9.8612e-05, 5.1461e-04],\n",
      "        [9.9396e-01, 4.6377e-04, 7.2399e-04, 7.9767e-04, 7.5620e-04, 5.0841e-04,\n",
      "         7.0273e-04, 1.4463e-03, 1.8766e-04, 4.5111e-04],\n",
      "        [9.9122e-01, 1.2773e-03, 1.8593e-04, 5.6068e-04, 2.1837e-03, 3.2886e-04,\n",
      "         6.0321e-04, 1.8250e-03, 1.2899e-03, 5.2250e-04],\n",
      "        [9.8915e-01, 1.9440e-04, 3.9333e-03, 4.3861e-05, 2.7893e-03, 7.7622e-04,\n",
      "         1.2914e-03, 7.3589e-04, 3.1199e-05, 1.0540e-03],\n",
      "        [9.9328e-01, 2.4895e-03, 9.8488e-04, 9.2644e-04, 9.0853e-04, 1.2011e-03,\n",
      "         7.2851e-05, 1.4408e-05, 9.9361e-05, 2.2919e-05],\n",
      "        [9.9513e-01, 1.4554e-03, 7.1541e-04, 3.8128e-04, 1.7781e-04, 2.7191e-04,\n",
      "         5.6135e-04, 7.3699e-04, 2.3914e-04, 3.2682e-04],\n",
      "        [9.9327e-01, 1.5113e-03, 8.9796e-04, 1.9412e-03, 4.1398e-04, 2.7268e-05,\n",
      "         8.2898e-05, 8.6786e-04, 4.8612e-04, 5.0503e-04],\n",
      "        [9.9345e-01, 8.1933e-05, 6.6819e-05, 1.8205e-04, 4.0878e-04, 1.8373e-03,\n",
      "         6.6565e-05, 1.0881e-03, 1.4864e-03, 1.3346e-03],\n",
      "        [9.9391e-01, 4.1967e-04, 5.8749e-05, 2.7093e-04, 1.0465e-03, 1.4139e-03,\n",
      "         1.3611e-03, 3.4395e-04, 8.8495e-04, 2.9209e-04],\n",
      "        [9.9121e-01, 6.0207e-04, 1.7530e-04, 1.3519e-04, 5.1005e-04, 9.5448e-04,\n",
      "         1.6391e-03, 3.9138e-03, 2.2473e-04, 6.3778e-04]])\n",
      "signal_params\n",
      "torch.Size([25, 3])\n",
      "p\n",
      "tensor([[ 1000., -1000., -1000.],\n",
      "        [-1000.,  1000., -1000.],\n",
      "        [-1000., -1000.,  1000.],\n",
      "        [ 1000., -1000., -1000.]])\n"
     ]
    }
   ],
   "source": [
    "print(toy_parms)\n",
    "print('m')\n",
    "print(m.shape)\n",
    "print(m)\n",
    "print('r')\n",
    "print(r.shape)\n",
    "print('collapsed_p')\n",
    "print(collapsed_p.shape)\n",
    "print(collapsed_p)\n",
    "print('pi')\n",
    "print(pi.shape)\n",
    "print(pi)\n",
    "print('signal_params')\n",
    "print(signal_params.shape)\n",
    "print('p')\n",
    "p = generator.params['p']\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b7446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0.])\n",
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0]])\n",
      "torch.Size([10000, 96])\n",
      "torch.Size([10000, 99])\n",
      "tensor([1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.cat((m, r.reshape(r.shape[0], -1)), 1)\n",
    "print(m[0,:])\n",
    "print(r[0,:])\n",
    "print((r.reshape(r.shape[0], -1)).shape)\n",
    "#print(torch.cat((m[0,:], r[0,:])))\n",
    "print(x.shape)\n",
    "print(x[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "580ccd8f-a634-4f6b-948b-59512cfb9405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_signals, num_states, num_references, hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        input_dim = num_signals + num_states * num_references\n",
    "        self.fc1 = nn.Linear(num_signals, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fcmu = nn.Linear(hidden, num_states)\n",
    "        self.fclv = nn.Linear(hidden, num_states)\n",
    "        self.bnmu = nn.BatchNorm1d(num_states, affine=True)\n",
    "        self.bnlv = nn.BatchNorm1d(num_states, affine=True)\n",
    "        \n",
    "    def forward(self, m, r):\n",
    "        # inputs = torch.cat((m, r.reshape(r.shape[0], -1)), 1)\n",
    "        inputs = m\n",
    "        h = F.softplus(self.fc1(inputs))\n",
    "        h = F.softplus(self.fc2(h))\n",
    "        h = self.drop(h)\n",
    "        logpi_loc = self.bnmu(self.fcmu(h))\n",
    "        logpi_logvar = self.bnmu(self.fclv(h))\n",
    "        logpi_scale = (0.5 * logpi_logvar).exp()\n",
    "        return logpi_loc, logpi_scale\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_states, num_signals, hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.beta = nn.Linear(num_states, num_signals, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(num_signals, affine=True)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # takes in the values of collapsed pi: probabilities of state \n",
    "        # assignments at each positions, and then apply a linear trans\n",
    "        # to get the probabilities of observing signals at each position\n",
    "        # --> vector size #signals\n",
    "        # used as parameters for bernoulli dist. to get obs. signals\n",
    "        inputs = self.drop(inputs)\n",
    "        beta = self.beta(inputs)\n",
    "        return torch.sigmoid(self.bn(beta)) # to transform to [0,1]\n",
    "    \n",
    "class TransferStateModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_signals, \n",
    "                 num_references,\n",
    "                 num_states,\n",
    "                 hidden, \n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.num_signals = num_signals\n",
    "        self.num_references = num_references\n",
    "        self.num_states = num_states\n",
    "        self.hidden = hidden\n",
    "        self.dropout = dropout\n",
    "        self.encoder = Encoder(num_signals, num_states, num_references, hidden, dropout)\n",
    "        self.decoder = Decoder(num_states, num_signals, hidden, dropout)\n",
    "                \n",
    "    # shapes: \n",
    "    #  m: (bins x signals) signal matrix\n",
    "    #  r: (bins x reference x state) indicator matrix\n",
    "    def model(self, m, r):\n",
    "        # flatten out the r indicator matrix\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate('bins', m.shape[0]):\n",
    "            logCpi_loc = m.new_zeros((m.shape[0], self.num_states))\n",
    "            logCpi_scale = m.new_ones((m.shape[0], self.num_states))\n",
    "            logCpi = pyro.sample(\n",
    "                'log_collapsedPi', dist.Normal(logCpi_loc, logCpi_scale).to_event(1))\n",
    "            Cpi = F.softmax(logCpi, -1)\n",
    "            signal_param = self.decoder(Cpi)          \n",
    "            pyro.sample('m', dist.Bernoulli(signal_param).to_event(1), obs=m)\n",
    "                \n",
    "    def guide(self, m, r):\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate('regions', m.shape[0]):\n",
    "            logpi_loc, logpi_scale = self.encoder(m, r)\n",
    "            logpi = pyro.sample(\n",
    "                'log_collapsedPi', dist.Normal(logpi_loc, logpi_scale).to_event(1))\n",
    "   # def p(self):\n",
    "   #     return self.decoder.p.weight.cpu().detach().T\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f435288-8ee2-4292-b360-c5525a2bb21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "serious_parms = {\n",
    "    'num_bins': 10000,\n",
    "    'num_references': 12,\n",
    "    'num_signals': 3,\n",
    "    'num_states': 8\n",
    "}\n",
    "\n",
    "serious_generator = ToyGenerator(**serious_parms, high_w=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3834289f-70c8-4037-9191-90e24c5df701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 12, 8])\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "pyro.set_rng_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "m = serious_generator.get_sampled_signals()\n",
    "r = serious_generator.get_ref_state_indicators()\n",
    "\n",
    "print(m.shape)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66a00519-7716-46a5-8428-b04758b9f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "state_model = TransferStateModel(\n",
    "    num_signals = serious_generator.num_signals,\n",
    "    num_references = serious_generator.num_references,\n",
    "    num_states = serious_generator.num_states,\n",
    "    hidden = 32,\n",
    "    dropout = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "becf8919-4c89-4a5f-b9bd-b82f471c77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abd7801b-8a50-4a3b-a9f8-88dac3aa99f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 100/100 [03:25<00:00,  2.06s/it, epoch_loss=1.86e-04]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100 #1000\n",
    "\n",
    "state_model.to(device)\n",
    "optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "svi = SVI(state_model.model, state_model.guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_batches = int(math.ceil(m.shape[0] / batch_size))\n",
    "\n",
    "bar = trange(num_epochs)\n",
    "for epoch in bar:\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        batch_m = m[i * batch_size:(i+1) * batch_size, :]\n",
    "        batch_r = r[i * batch_size:(i+1) * batch_size, :, :]\n",
    "        loss = svi.step(batch_m, batch_r)\n",
    "        running_loss += loss / batch_m.size(0)\n",
    "        \n",
    "    bar.set_postfix(epoch_loss='{:.2e}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9d0bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 8])\n",
      "tensor([[ 1.4282e-08, -1.1886e-21,  6.2858e-41,  ..., -1.7508e-08,\n",
      "         -7.4117e-12, -2.7698e-11],\n",
      "        [ 1.4282e-08, -6.0382e-22, -2.4174e-40,  ..., -1.2261e-08,\n",
      "         -7.4117e-12, -2.7698e-11],\n",
      "        [ 1.4282e-08, -2.4395e-22,  1.1200e-39,  ...,  1.7537e-08,\n",
      "         -7.4117e-12, -2.7698e-11],\n",
      "        ...,\n",
      "        [ 1.4282e-08,  1.0606e-21,  2.7812e-40,  ...,  2.0605e-08,\n",
      "         -7.4117e-12, -2.7698e-11],\n",
      "        [ 1.4282e-08, -4.2389e-22,  5.5285e-40,  ..., -8.2385e-10,\n",
      "         -7.4117e-12, -2.7698e-11],\n",
      "        [ 1.4282e-08, -3.3392e-22,  8.0050e-40,  ..., -4.3567e-09,\n",
      "         -7.4117e-12, -2.7698e-11]], grad_fn=<NativeBatchNormBackward>)\n",
      "tensor([[0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        ...,\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250],\n",
      "        [0.1250, 0.1250, 0.1250,  ..., 0.1250, 0.1250, 0.1250]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "tensor([ 1.4282e-08, -1.1886e-21,  6.2858e-41,  6.4954e-08,  5.9182e-33,\n",
      "        -1.7508e-08, -7.4117e-12, -2.7698e-11], grad_fn=<SliceBackward>)\n",
      "tensor([ 1.4282e-01, -1.1886e-14,  6.2858e-34,  6.4954e-01,  5.9182e-26,\n",
      "        -1.7508e-01, -7.4117e-05, -2.7698e-04], grad_fn=<MulBackward0>)\n",
      "tensor([1.1535, 1.0000, 1.0000, 1.9147, 1.0000, 0.8394, 0.9999, 0.9997],\n",
      "       grad_fn=<ExpBackward>)\n",
      "tensor([0.1295, 0.1123, 0.1123, 0.2150, 0.1123, 0.0942, 0.1123, 0.1122],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "logpi_loc, logpi_scale = state_model.encoder(m, r)\n",
    "print(logpi_loc.shape)\n",
    "print(logpi_loc)\n",
    "print(F.softmax(logpi_loc, 1))\n",
    "x = logpi_loc[0,:] * 1.0e7\n",
    "print(logpi_loc[0,:])\n",
    "print(x)\n",
    "print(x.exp())\n",
    "print(F.softmax(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21f17711-376e-4bd2-8d7c-e21b7a735084",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferStateModelPostHoc:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def sample_one_posterior_pi(self, loc, scale):\n",
    "        logpi = dist.Normal(loc, scale).sample()\n",
    "        return F.softmax(logpi, -1)\n",
    "    \n",
    "    def get_posterior_pi(self, m, r, num_samples = 1000):\n",
    "        running_sum = torch.zeros(m.shape[0], self.model.num_states[0])\n",
    "        running_sum_squares = torch.zeros(m.shape[0], self.model.num_states[0])\n",
    "        for _ in range(num_samples):\n",
    "            loc, scale = self.model.encoder(m, r)\n",
    "            logpi = dist.Normal(loc, scale).sample()\n",
    "            pi = F.softmax(logpi, -1)\n",
    "            running_sum += pi\n",
    "            running_sum_squares += (pi ** 2)\n",
    "            \n",
    "        return {\n",
    "            'posterior_mean': running_sum / num_samples, \n",
    "            'posterior_std': torch.sqrt(running_sum_squares / num_samples),\n",
    "            'hacky_pi': F.softmax(running_sum, dim=1)\n",
    "        }\n",
    "    \n",
    "    def do_posterior_stuff(self, m, r, num_samples=100):\n",
    "        pi = self.get_posterior_pi(m, r, num_samples=num_samples)\n",
    "        signal_param = self.model.decoder(pi['hacky_pi'])\n",
    "        m = (signal_param > 0.5).float()\n",
    "        return {\n",
    "            'pi': pi,\n",
    "            'signal_param': signal_param,\n",
    "            'm': m\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1506,
   "id": "d45a4a1c-8b9f-46be-815e-44e83bf5edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_stuff=TransferStateModelPostHoc(state_model).do_posterior_stuff(m, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "id": "71058f9f-3b37-4b8a-bfa1-b3bb07ef410a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5032, 0.0578, 0.0120, 0.0403, 0.3583, 0.0105, 0.0065, 0.0114],\n",
       "        [0.0216, 0.0794, 0.1330, 0.0898, 0.1676, 0.2295, 0.1995, 0.0796],\n",
       "        [0.1161, 0.0175, 0.0290, 0.0998, 0.0320, 0.3084, 0.3318, 0.0654],\n",
       "        [0.1868, 0.1690, 0.1083, 0.0958, 0.0332, 0.0401, 0.0897, 0.2772],\n",
       "        [0.1260, 0.0141, 0.3549, 0.0319, 0.2706, 0.0131, 0.0246, 0.1647]])"
      ]
     },
     "execution_count": 1507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_stuff['pi']['hacky_pi'][0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1508,
   "id": "6461f326-71e2-4c86-b5f7-a0919bae24a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5006, 0.4954, 0.5011],\n",
       "        [0.5001, 0.4963, 0.5003],\n",
       "        [0.4999, 0.4941, 0.5000],\n",
       "        [0.5000, 0.5066, 0.4995],\n",
       "        [0.5006, 0.4978, 0.5007]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 1508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_stuff['signal_param'][0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1462,
   "id": "0dad0b3c-ccdc-48d5-b554-df4cafd22b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0209, 0.0678, 0.5084, 0.1500, 0.0091, 0.0412, 0.0963, 0.1063],\n",
       "        [0.0107, 0.3958, 0.1768, 0.0582, 0.0687, 0.0120, 0.1908, 0.0870],\n",
       "        [0.0418, 0.0814, 0.0569, 0.2400, 0.4487, 0.0435, 0.0118, 0.0760],\n",
       "        [0.0871, 0.0377, 0.0634, 0.0825, 0.2295, 0.0326, 0.0515, 0.4157],\n",
       "        [0.0241, 0.7570, 0.0145, 0.0014, 0.0792, 0.0856, 0.0302, 0.0081]])"
      ]
     },
     "execution_count": 1462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_posterior['pi']['hacky_pi'][0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1443,
   "id": "37dcb68c-8a3e-4db7-a0f1-2536f901af4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5001, 0.5001, 0.4995],\n",
       "        [0.5002, 0.4997, 0.5001],\n",
       "        [0.4997, 0.5002, 0.4995],\n",
       "        [0.5000, 0.5008, 0.4993],\n",
       "        [0.5002, 0.5001, 0.5012]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 1443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_posterior['signal_param'][0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1444,
   "id": "d6ee4052-0cd6-4892-9d7d-9700a043ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.],\n",
       "        [1., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 1444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_posterior['m'][0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1445,
   "id": "44ac75c5-a14b-4fbe-b7a5-b7d37b0be78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 1445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "id": "f802077e-64e2-4e32-b9c7-ed14eb245613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3],\n",
      "        [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]])\n",
      "torch.Size([10, 12, 4])\n",
      "torch.Size([10, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4, 10])"
      ]
     },
     "execution_count": 1350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(10, 12)\n",
    "for i in range(10):\n",
    "    for j in range(12):\n",
    "        a[i,j] = j % 4\n",
    "        \n",
    "print(a.long())\n",
    "b = F.one_hot(a.long(), num_classes=4)\n",
    "print(b.shape)\n",
    "c = torch.rand(10,12)\n",
    "print(c.shape)\n",
    "torch.matmul(torch.transpose(b,2,1).float(),c.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "id": "e9409939-990e-4a8f-8caf-bdf531b7d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0481, 0.7089, 1.9728, 1.4895])"
      ]
     },
     "execution_count": 1356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(b[0,:,:].T.float(), c[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1414,
   "id": "21816bfb-5261-44cc-9476-42b4b149a3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 1414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "id": "a033372b-9d8e-4334-93e6-c2efc6b50ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14, 15],\n",
      "         [16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "        [ 3,  4,  5, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 1423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.arange(2*3*4).reshape(2,3,4)\n",
    "print(a)\n",
    "print(a.reshape(a.shape[0], -1))\n",
    "c=torch.arange(2*3).reshape(2,3)\n",
    "print(c)\n",
    "torch.cat((c, a.reshape(a.shape[0], -1)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "10a5f369-e35b-4181-ab57-1c8394b2a95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.]]),\n",
       " tensor([[[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " \n",
       "         [[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "          [0, 0, 0, 1, 0, 0, 0, 0]]]))"
      ]
     },
     "execution_count": 1446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0:5,:], r[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4696643b-fe90-4cd2-b748-4e7e457d5f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
