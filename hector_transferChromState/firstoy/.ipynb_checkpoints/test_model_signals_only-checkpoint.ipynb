{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1df08ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch.nn.functional as F\n",
    "from pyro.infer import SVI, TraceMeanField_ELBO\n",
    "from tqdm import trange\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66371fc1",
   "metadata": {},
   "source": [
    "## Class to generate toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d444da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "M: # regions\n",
    "N: # bins per region\n",
    "L: # signals (marks)\n",
    "alpha: params of dirichlet prior over reference epigenomics\n",
    "beta: ref --> sample state categorical distribution\n",
    "p: state --> signal bernoulli distribution \n",
    "r: reference state at each bin. one-hot encoding, matrix size : #bins * #ref * #states\n",
    "theta: the mixture probabilities of reference ethetagenome\n",
    "'''\n",
    "\n",
    "class CircularStateGenerator:\n",
    "    # Within the number of references, there is a group of references that will be similar to the \n",
    "    # sample of interests in terms of state assignments\n",
    "    def __init__(self,  \n",
    "                 num_bins=5, \n",
    "                 num_references=10, \n",
    "                 num_groups=3,\n",
    "                 state_vary_rate=0.01, \n",
    "                 # fraction of the genome where the state assignments among references of the same group are diff\n",
    "                 num_signals=3,\n",
    "                 num_states=5,\n",
    "                 high_w=100):\n",
    "        self.num_bins = num_bins\n",
    "        self.num_references = num_references\n",
    "        self.num_groups = num_groups\n",
    "        self.state_vary_rate = state_vary_rate\n",
    "        self.num_signals = num_signals\n",
    "        self.num_states = num_states\n",
    "        self.high_w = high_w\n",
    "        self.sample = None\n",
    "        self.params = self.set_params()\n",
    "    \n",
    "        \n",
    "    # parameter of state->signal distributions\n",
    "    # shape is (num_states, num_signals)\n",
    "    def generate_param_p(self):\n",
    "        p = torch.zeros((self.num_states, self.num_signals))\n",
    "        for i in range(self.num_states):\n",
    "            w = -self.high_w * torch.ones(self.num_signals)\n",
    "            w[i % self.num_signals] = self.high_w\n",
    "            p[i,:] = w\n",
    "        return p\n",
    "    \n",
    "    # generate a state assignment tensor\n",
    "    # shape is (num_regions, num_bins_per_region, num_references)\n",
    "    def generate_ref_states(self):\n",
    "        # this is code for the case where we want varied state patterns from each reference\n",
    "        # and that there are actually groups of references that are similar to each other\n",
    "        num_ref_per_groups = np.ceil(self.num_references/self.num_groups).astype(int)\n",
    "        sample_r = torch.zeros(self.num_states, self.num_groups)\n",
    "        for i in range(self.num_groups):\n",
    "            sample_r[:,i] = torch.arange(self.num_states).roll(i)\n",
    "            # each group has a circular permutation of states that are characteristics to that group\n",
    "        sample_r = sample_r.repeat(np.ceil(self.num_bins / self.num_states).astype(int), 1)\n",
    "        # now r is just a repeated sequence of sample_r\n",
    "        r = torch.zeros(sample_r.shape[0], self.num_references)\n",
    "        for i in range(self.num_references):\n",
    "            r[:,i] = sample_r[:, i % self.num_groups]\n",
    "        # now we will start to introduce some random changes to the state assignments among references from\n",
    "        # the same groups\n",
    "        num_change = int(self.state_vary_rate * self.num_bins)\n",
    "        for i in range(self.num_states, self.num_references): \n",
    "            # for the first num_states columns, keep all the state assignments\n",
    "            # if num_references < num_states, this loop will not be called\n",
    "            org_r = r[:,i]\n",
    "            indices_to_change = np.random.choice(self.num_bins, num_change)\n",
    "            indices_to_change = torch.tensor(indices_to_change).type(torch.LongTensor)\n",
    "            states_to_change = torch.tensor(np.random.choice(self.num_states, num_change)).float()\n",
    "            r[indices_to_change,i] = states_to_change\n",
    "        r = r[:self.num_bins,:self.num_references]\n",
    "        return r.long() # num_bins, num_references --> values: state-0-based \n",
    "    \n",
    "    # set parameters of the data generator\n",
    "    def set_params(self):\n",
    "        # parameters of the dirichlet over references\n",
    "        # same one for every region\n",
    "        # very high probability that generated sample looks like\n",
    "        # reference 0\n",
    "        # shape is (num_references,)\n",
    "        alpha = torch.ones(self.num_references)\n",
    "        num_ref_per_groups = np.ceil(self.num_references/self.num_groups).astype(int)\n",
    "        for i in range(self.num_references):\n",
    "            if i % self.num_groups == 0:\n",
    "                alpha[i] = self.high_w # all refs in group 1 will be more similar to sample of interest\n",
    "        \n",
    "        # parameters of bernoulli distribution for each signal\n",
    "        # for each state\n",
    "        # shape is (num_states, num_signals)\n",
    "        p = self.generate_param_p()\n",
    "        \n",
    "        # an indicator matrix along genome of the state for \n",
    "        # each refenrece\n",
    "        # shape is (num_regions, num_bins_per_region, num_states, num_references)\n",
    "        ref_states_indicator = F.one_hot(self.generate_ref_states(), self.num_states)\n",
    "        params = {\n",
    "            'alpha': alpha,\n",
    "            'p': p,\n",
    "            'ref_states_indicator': ref_states_indicator\n",
    "        }\n",
    "        self.params = params\n",
    "        return params\n",
    "        \n",
    "    # collapse a prob vector over references to a prob vector over states\n",
    "    # takes the cross product of prob vector theta and reference state indicator matrix r\n",
    "    # shapes:\n",
    "    #  theta: (None, num_references)\n",
    "    #  r: (None, num_references, num_states)\n",
    "    #  out: (None, num_states)\n",
    "    def collapse_theta(self, theta, r=None):\n",
    "        if r is None:\n",
    "            assert self.params is not None\n",
    "            r = self.params['ref_states_indicator']\n",
    "            \n",
    "        r = r.float()\n",
    "        collapsed_theta = torch.zeros(theta.shape[0], r.shape[2])\n",
    "        for i in range(theta.shape[0]):\n",
    "            collapsed_theta[i,:] = torch.matmul(r[i,:,:].T, theta[i,:])\n",
    "        return collapsed_theta\n",
    "    \n",
    "    def generate_sample(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "            \n",
    "        r = self.params['ref_states_indicator']\n",
    "                \n",
    "        # generate reference distribution for each region\n",
    "        with pyro.plate('bins', self.num_bins):\n",
    "            # theta is shape (num_regions, num_references)\n",
    "            theta = pyro.sample('theta', dist.Dirichlet(self.params['alpha']))\n",
    "            # collapse the reference distribution for each bin to a \n",
    "            # state distribution \n",
    "            collapsed_theta = self.collapse_theta(theta, r)\n",
    "\n",
    "            signal_params = torch.sigmoid(torch.matmul(collapsed_theta, self.params['p']))\n",
    "            m = pyro.sample('m', dist.Bernoulli(signal_params).to_event(1))\n",
    "\n",
    "        result = {\n",
    "            'theta': theta,\n",
    "            'm': m\n",
    "        }\n",
    "        self.sample = result\n",
    "        return self.sample\n",
    "    \n",
    "\n",
    "    def get_sampled_collapsed_theta(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        theta = self.sample['theta']\n",
    "        return self.collapse_theta(theta)\n",
    "    \n",
    "    def get_sampled_signals(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['m']\n",
    "    \n",
    "    def get_sampled_theta(self):\n",
    "        if self.sample is None:\n",
    "            self.generate_sample()\n",
    "        return self.sample['theta']\n",
    "    \n",
    "    def get_signal_parms(self):\n",
    "        collapsed_theta = self.get_sampled_collapsed_theta()\n",
    "        return torch.sigmoid(torch.matmul(collapsed_theta, self.params['p']))\n",
    "    \n",
    "    def get_ref_state_indicators(self):\n",
    "        if self.params is None:\n",
    "            self.set_params()\n",
    "        return self.params['ref_states_indicator']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbf6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "serious_parms = {\n",
    "    'num_bins': 10000,\n",
    "    'num_references': 10,\n",
    "    'num_groups': 3,\n",
    "    'state_vary_rate': 0.003,\n",
    "    'num_signals': 3,\n",
    "    'num_states': 3,\n",
    "    'high_w': 100\n",
    "}\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "pyro.set_rng_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "generator = CircularStateGenerator(**serious_parms)\n",
    "\n",
    "m = generator.get_sampled_signals()\n",
    "r = generator.get_ref_state_indicators()\n",
    "collapsed_theta = generator.get_sampled_collapsed_theta()\n",
    "theta = generator.get_sampled_theta()\n",
    "signal_params = generator.get_signal_parms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa6a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_bins': 10000, 'num_references': 10, 'num_groups': 3, 'state_vary_rate': 0.003, 'num_signals': 3, 'num_states': 3, 'high_w': 100}\n",
      "m: obs. signals at each position\n",
      "torch.Size([10000, 3])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "r: reference epigenome state indicator at each position\n",
      "torch.Size([10000, 10, 3])\n",
      "collapsed_theta: state assignment at each position\n",
      "torch.Size([10000, 3])\n",
      "tensor([[0.9912, 0.0020, 0.0068],\n",
      "        [0.0109, 0.9862, 0.0029],\n",
      "        [0.0024, 0.0276, 0.9700],\n",
      "        ...,\n",
      "        [0.0027, 0.9882, 0.0091],\n",
      "        [0.0047, 0.0035, 0.9917],\n",
      "        [0.9931, 0.0049, 0.0019]])\n",
      "theta: the reference mixture at each position\n",
      "torch.Size([10000, 10])\n",
      "tensor([[2.8926e-01, 1.1351e-03, 2.8802e-04,  ..., 5.0673e-03, 7.5635e-04,\n",
      "         2.5826e-01],\n",
      "        [2.4719e-01, 6.4616e-03, 1.9981e-03,  ..., 2.9050e-03, 3.1032e-04,\n",
      "         2.2649e-01],\n",
      "        [2.3822e-01, 2.2335e-03, 2.7438e-04,  ..., 1.5360e-02, 6.2279e-04,\n",
      "         2.3243e-01],\n",
      "        ...,\n",
      "        [2.3123e-01, 1.0679e-03, 3.4313e-03,  ..., 4.5041e-04, 3.5226e-03,\n",
      "         2.2472e-01],\n",
      "        [2.4472e-01, 2.5040e-06, 1.5063e-03,  ..., 1.4921e-03, 3.1532e-03,\n",
      "         2.5970e-01],\n",
      "        [2.7309e-01, 7.5642e-04, 3.5097e-03,  ..., 2.9428e-04, 1.0766e-03,\n",
      "         2.5016e-01]])\n",
      "signal_params: bernoulli dist. params generating signal at each position\n",
      "torch.Size([10000, 3])\n",
      "p\n",
      "tensor([[ 100., -100., -100.],\n",
      "        [-100.,  100., -100.],\n",
      "        [-100., -100.,  100.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(serious_parms)\n",
    "print('m: obs. signals at each position')\n",
    "print(m.shape)\n",
    "print(m)\n",
    "print('r: reference epigenome state indicator at each position')\n",
    "print(r.shape)\n",
    "print('collapsed_theta: state assignment at each position')\n",
    "print(collapsed_theta.shape)\n",
    "print(collapsed_theta)\n",
    "print('theta: the reference mixture at each position')\n",
    "print(theta.shape)\n",
    "print(theta)\n",
    "print('signal_params: bernoulli dist. params generating signal at each position')\n",
    "print(signal_params.shape)\n",
    "print('p')\n",
    "p = generator.params['p']\n",
    "print (p)\n",
    "print (p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa990fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3334., 3333., 3333.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many positions that emit each of the mark\n",
    "torch.sum(m, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "856ed425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data of collapsed theta (--> state probabilities at each position)\n",
    "collapsed_theta = pd.DataFrame(collapsed_theta.numpy())\n",
    "collapsed_theta['max_state'] = collapsed_theta.idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed411690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2  max_state\n",
      "0  0.991196  0.002015  0.006789          0\n",
      "1  0.010920  0.986210  0.002871          1\n",
      "2  0.002429  0.027560  0.970011          2\n",
      "3  0.984627  0.006708  0.008665          0\n",
      "4  0.008432  0.983749  0.007819          1\n"
     ]
    }
   ],
   "source": [
    "print(collapsed_theta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f2cc0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, num_signals, num_states, num_references, hidden, dropout):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.drop = nn.Dropout(dropout)\n",
    "\t\tinput_dim = num_signals + num_states * num_references\n",
    "\t\tself.fc1 = nn.Linear(num_signals, hidden)\n",
    "\t\tself.fc2 = nn.Linear(hidden, hidden)\n",
    "\t\tself.fcmu = nn.Linear(hidden, num_states)\n",
    "\t\tself.fclv = nn.Linear(hidden, num_states)\n",
    "\n",
    "\tdef forward(self, m):\n",
    "\t\tinputs = m\n",
    "\t\th = F.softplus(self.fc1(inputs))\n",
    "\t\th = F.softplus(self.fc2(h))\n",
    "\t\th = self.drop(h)\n",
    "\t\tlogpi_loc = F.softplus(self.fcmu(h))\n",
    "\t\tlogpi_logvar = self.fclv(h)\n",
    "\t\tlogpi_loc = self.drop(logpi_loc)\n",
    "\t\tlogpi_scale = (0.5 * logpi_logvar).exp()\n",
    "\t\treturn logpi_loc, logpi_scale\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, num_states, num_signals, hidden, dropout):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.drop = nn.Dropout(dropout)\n",
    "\t\tself.beta = nn.Linear(num_states, num_signals, bias=False)\n",
    "\t\tself.bn = nn.BatchNorm1d(num_signals, affine=True)\n",
    "\n",
    "\tdef forward(self, inputs):\n",
    "\t\t# takes in the values of collapsed pi: probabilities of state \n",
    "\t\t# assignments at each positions, and then apply a linear trans\n",
    "\t\t# to get the probabilities of observing signals at each position\n",
    "\t\t# --> vector size #signals\n",
    "\t\t# used as parameters for bernoulli dist. to get obs. signals\n",
    "\t\tinputs = self.drop(inputs)\n",
    "\t\tbeta = self.beta(inputs)\n",
    "\t\treturn torch.sigmoid(beta) # to transform to [0,1]\n",
    "    \n",
    "class model_Signals(nn.Module):\n",
    "\tdef __init__(self, num_signals, num_references, num_states, hidden, dropout):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.num_signals = num_signals\n",
    "\t\tself.num_references = num_references\n",
    "\t\tself.num_states = num_states\n",
    "\t\tself.hidden = hidden\n",
    "\t\tself.dropout = dropout\n",
    "\t\tself.encoder = Encoder(num_signals, num_states, num_references, hidden, dropout)\n",
    "\t\tself.decoder = Decoder(num_states, num_signals, hidden, dropout)\n",
    "\n",
    "\t# shapes: \n",
    "\t#  m: (bins x signals) signal matrix\n",
    "\t#  r: (bins x reference x state) indicator matrix\n",
    "\tdef model(self, m):\n",
    "\t\t# flatten out the r indicator matrix\n",
    "\t\tpyro.module(\"decoder\", self.decoder)\n",
    "\t\twith pyro.plate('bins', m.shape[0]):\n",
    "\t\t\tlogCpi_loc = m.new_zeros((m.shape[0], self.num_states))\n",
    "\t\t\tlogCpi_scale = m.new_ones((m.shape[0], self.num_states))\n",
    "\t\t\tlogCpi = pyro.sample('log_collapsedPi', dist.Normal(logCpi_loc, logCpi_scale).to_event(1))\n",
    "\t\t\tCpi = F.softmax(logCpi, -1) # softmax is right because Cpi ~ LogNormal\n",
    "\t\t\tsignal_param = self.decoder(Cpi)          \n",
    "\t\t\tpyro.sample('m', dist.Bernoulli(signal_param).to_event(1), obs=m)\n",
    "\t            \n",
    "\tdef guide(self, m):\n",
    "\t\tpyro.module(\"encoder\", self.encoder)\n",
    "\t\twith pyro.plate('bins', m.shape[0]):\n",
    "\t\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\t\tlogpi = pyro.sample('log_collapsedPi', dist.Normal(logpi_loc, logpi_scale).to_event(1))\n",
    "\n",
    "\tdef predict_state_assignment(self, m):\n",
    "\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\tCpi = F.softmax(logpi_loc, -1)\n",
    "\t\treturn(Cpi)\n",
    "\n",
    "\tdef write_predicted_state_assignment(self, m, output_fn):\n",
    "\t\tCpi = self.predict_state_assignment(m)\n",
    "\t\tdf = pd.DataFrame(Cpi.detach().numpy())\n",
    "\t\tdf['max_state'] = df.idxmax(axis =1)\n",
    "\t\tdf.to_csv(output_fn, header = True, index = False, sep = '\\t', compression = 'gzip')\n",
    "\t\treturn\n",
    "\t\t\n",
    "\tdef beta(self):\n",
    "\t\treturn self.decoder.beta.weight.cpu().detach().T\n",
    "\n",
    "\tdef generate_reconstructed_data(self, m):\n",
    "\t\t'''\n",
    "\t\tm: num_bins, num_signals\n",
    "\t\tlogpi_loc, logpi_scale: num_bins, num_states\n",
    "\t\tsignal_param: num_bins, num_signals\n",
    "\t\t'''\n",
    "\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\tCpi = F.softmax(logpi_loc, -1)\n",
    "\t\tsignal_param = self.decoder(Cpi) \n",
    "\t\tre_m = pyro.sample('reconstructed_m', dist.Bernoulli(signal_param).to_event(1))\n",
    "\t\treturn (re_m)\n",
    "\n",
    "\tdef get_percentage_correct_reconstruct(self, m):\n",
    "\t\t# m and r can be different from the m and r used in training\n",
    "\t\tre_m = self.generate_reconstructed_data(m)\n",
    "\t\ttotal_m_entries = re_m.shape[0] * re_m.shape[1]\n",
    "\t\tsignals_CR = (re_m==m).sum() # correct reconstruct entries of signals\n",
    "\t\tratio_m_CR = (signals_CR / total_m_entries).item()\n",
    "\t\treturn ratio_m_CR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcc24cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████| 1000/1000 [02:38<00:00,  6.30it/s, epoch_loss=9.64e+01]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 1000\n",
    "pyro.clear_param_store()\n",
    "state_model = model_Signals(\n",
    "    num_signals = generator.num_signals,\n",
    "    num_references = generator.num_references,\n",
    "    num_states = generator.num_states,\n",
    "    hidden = 32,\n",
    "    dropout = 0.2)\n",
    "state_model.to(device)\n",
    "optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "svi = SVI(state_model.model, state_model.guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_batches = int(math.ceil(m.shape[0] / batch_size))\n",
    "\n",
    "bar = trange(num_epochs)\n",
    "for epoch in bar:\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        batch_m = m[i * batch_size:(i+1) * batch_size, :]\n",
    "        batch_r = r[i * batch_size:(i+1) * batch_size, :, :]\n",
    "        loss = svi.step(batch_m)\n",
    "        running_loss += loss / batch_m.size(0)\n",
    "        \n",
    "    bar.set_postfix(epoch_loss='{:.2e}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1fdfc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(1446)\n",
      "tensor(16433)\n"
     ]
    }
   ],
   "source": [
    "re_m = state_model.generate_reconstructed_data(m)\n",
    "print(re_m.shape)\n",
    "print(m)\n",
    "print(re_m)\n",
    "print(((m==re_m).all(dim=1)).sum())\n",
    "print((m==re_m).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e072267",
   "metadata": {},
   "source": [
    "Evaluating the state posterior, compared with generated collapsed_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f455ac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>max_state_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>max_state_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333331</td>\n",
       "      <td>0.333331</td>\n",
       "      <td>0.333339</td>\n",
       "      <td>2</td>\n",
       "      <td>0.991196</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.332853</td>\n",
       "      <td>0.332846</td>\n",
       "      <td>0.334301</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.986210</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333273</td>\n",
       "      <td>0.333273</td>\n",
       "      <td>0.333454</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>0.970011</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333319</td>\n",
       "      <td>0.333319</td>\n",
       "      <td>0.333363</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984627</td>\n",
       "      <td>0.006708</td>\n",
       "      <td>0.008665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.332854</td>\n",
       "      <td>0.332846</td>\n",
       "      <td>0.334300</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.983749</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.333261</td>\n",
       "      <td>0.333261</td>\n",
       "      <td>0.333478</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.974994</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.333329</td>\n",
       "      <td>0.333329</td>\n",
       "      <td>0.333341</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.332976</td>\n",
       "      <td>0.332979</td>\n",
       "      <td>0.334045</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.988218</td>\n",
       "      <td>0.009128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.333271</td>\n",
       "      <td>0.333271</td>\n",
       "      <td>0.333459</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.333332</td>\n",
       "      <td>0.333336</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993128</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_x       1_x       2_x  max_state_x       0_y       1_y       2_y  \\\n",
       "0     0.333331  0.333331  0.333339            2  0.991196  0.002015  0.006789   \n",
       "1     0.332853  0.332846  0.334301            2  0.010920  0.986210  0.002871   \n",
       "2     0.333273  0.333273  0.333454            2  0.002429  0.027560  0.970011   \n",
       "3     0.333319  0.333319  0.333363            2  0.984627  0.006708  0.008665   \n",
       "4     0.332854  0.332846  0.334300            2  0.008432  0.983749  0.007819   \n",
       "...        ...       ...       ...          ...       ...       ...       ...   \n",
       "9995  0.333261  0.333261  0.333478            2  0.011204  0.013802  0.974994   \n",
       "9996  0.333329  0.333329  0.333341            2  0.987448  0.007399  0.005153   \n",
       "9997  0.332976  0.332979  0.334045            2  0.002654  0.988218  0.009128   \n",
       "9998  0.333271  0.333271  0.333459            2  0.004716  0.003536  0.991748   \n",
       "9999  0.333332  0.333332  0.333336            2  0.993128  0.004935  0.001937   \n",
       "\n",
       "      max_state_y  \n",
       "0               0  \n",
       "1               1  \n",
       "2               2  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "9995            2  \n",
       "9996            0  \n",
       "9997            1  \n",
       "9998            2  \n",
       "9999            0  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cpi = state_model.predict_state_assignment(m)\n",
    "df = pd.DataFrame(Cpi.detach().numpy())\n",
    "df['max_state'] = df.idxmax(axis =1)\n",
    "df = df.merge(collapsed_theta, left_index = True, right_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81280258",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\tdef __init__(self, num_signals, num_states, num_references, hidden, dropout):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.drop = nn.Dropout(dropout)\n",
    "\t\tinput_dim = num_signals + num_states * num_references\n",
    "\t\tself.fc1 = nn.Linear(num_signals, hidden)\n",
    "\t\tself.fc2 = nn.Linear(hidden, hidden)\n",
    "\t\tself.fcmu = nn.Linear(hidden, num_states)\n",
    "\t\tself.fclv = nn.Linear(hidden, num_states)\n",
    "\n",
    "\tdef forward(self, m):\n",
    "\t\tinputs = m\n",
    "\t\th = F.softplus(self.fc1(inputs))\n",
    "\t\th = F.softplus(self.fc2(h))\n",
    "\t\th = self.drop(h)\n",
    "\t\tlogpi_loc = F.softplus(self.fcmu(h))\n",
    "\t\tlogpi_logvar = self.fclv(h)\n",
    "\t\tlogpi_loc = self.drop(logpi_loc)\n",
    "\t\tlogpi_scale = (0.5 * logpi_logvar).exp()\n",
    "\t\treturn logpi_loc, logpi_scale\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\tdef __init__(self, num_states, num_signals, hidden, dropout, fixed_signalP):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.drop = nn.Dropout(dropout)\n",
    "\t\tself.beta = nn.Linear(num_states, num_signals, bias=False)\n",
    "\t\tself.bn = nn.BatchNorm1d(num_signals, affine=True)\n",
    "\t\tself.fixed_signalP = fixed_signalP\n",
    "\n",
    "\tdef forward(self, inputs):\n",
    "\t\t# takes in the values of collapsed pi (inputs): probabilities of state \n",
    "\t\t# assignments at each positions, and then multiply by fixed_signalP (beta)\n",
    "\t\t# to get the probabilities of observing signals at each position\n",
    "\t\t# --> vector size #signals\n",
    "\t\t# used as parameters for bernoulli dist. to get obs. signals\n",
    "\t\t# fixed_signalP: #states, #marks, from the random number generator\n",
    "\t\tsignal_param = torch.matmul(inputs, self.fixed_signalP)\n",
    "\t\treturn torch.sigmoid(signal_param) # to transform to [0,1]\n",
    "    \n",
    "class model_signals_only_fixedBeta(nn.Module):\n",
    "\tdef __init__(self, num_signals, num_references, num_states, hidden, dropout, fixed_signalP):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.num_signals = num_signals\n",
    "\t\tself.num_references = num_references\n",
    "\t\tself.num_states = num_states\n",
    "\t\tself.fixed_signalP = fixed_signalP\n",
    "\t\tself.hidden = hidden\n",
    "\t\tself.dropout = dropout\n",
    "\t\tself.encoder = Encoder(num_signals, num_states, num_references, hidden, dropout)\n",
    "\t\tself.decoder = Decoder(num_states, num_signals, hidden, dropout, fixed_signalP)\n",
    "\n",
    "\t# shapes: \n",
    "\t#  m: (bins x signals) signal matrix\n",
    "\t#  r: (bins x reference x state) indicator matrix\n",
    "\tdef model(self, m):\n",
    "\t\t# flatten out the r indicator matrix\n",
    "\t\tpyro.module(\"decoder\", self.decoder)\n",
    "\t\twith pyro.plate('bins', m.shape[0]):\n",
    "\t\t\tlogCpi_loc = m.new_zeros((m.shape[0], self.num_states))\n",
    "\t\t\tlogCpi_scale = m.new_ones((m.shape[0], self.num_states))\n",
    "\t\t\tlogCpi = pyro.sample('log_collapsedPi', dist.Normal(logCpi_loc, logCpi_scale).to_event(1))\n",
    "\t\t\tCpi = logCpi.exp()\t\t\t\n",
    "\t\t\tCpi = F.softmax(logCpi, -1)\n",
    "\t\t\tsignal_param = self.decoder(Cpi)          \n",
    "\t\t\tpyro.sample('m', dist.Bernoulli(signal_param).to_event(1), obs=m)\n",
    "\t            \n",
    "\tdef guide(self, m):\n",
    "\t\tpyro.module(\"encoder\", self.encoder)\n",
    "\t\twith pyro.plate('bins', m.shape[0]):\n",
    "\t\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\t\tlogpi = pyro.sample('log_collapsedPi', dist.Normal(logpi_loc, logpi_scale).to_event(1))\n",
    "\n",
    "\tdef predict_state_assignment(self, m):\n",
    "\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\tCpi = F.softmax(logpi_loc, -1)\n",
    "\t\treturn(Cpi)\n",
    "\n",
    "\tdef write_predicted_state_assignment(self, m, output_fn):\n",
    "\t\tCpi = self.predict_state_assignment(m)\n",
    "\t\tdf = pd.DataFrame(Cpi.detach().numpy())\n",
    "\t\tdf['max_state'] = df.idxmax(axis =1)\n",
    "\t\tdf.to_csv(output_fn, header = True, index = False, sep = '\\t', compression = 'gzip')\n",
    "\t\treturn\n",
    "\n",
    "\tdef generate_reconstructed_data(self, m):\n",
    "\t\t'''\n",
    "\t\tm: num_bins, num_signals\n",
    "\t\tlogpi_loc, logpi_scale: num_bins, num_states\n",
    "\t\tsignal_param: num_bins, num_signals\n",
    "\t\t'''\n",
    "\t\tlogpi_loc, logpi_scale = self.encoder(m)\n",
    "\t\tCpi = F.softmax(logpi_loc, -1)\n",
    "\t\tsignal_param = self.decoder(Cpi) \n",
    "\t\tre_m = pyro.sample('reconstructed_m', dist.Bernoulli(signal_param).to_event(1))\n",
    "\t\treturn (re_m)\n",
    "\n",
    "\tdef get_percentage_correct_reconstruct(self, m):\n",
    "\t\t# m can be different from the m used in training\n",
    "\t\tre_m = self.generate_reconstructed_data(m)\n",
    "\t\ttotal_m_entries = re_m.shape[0] * re_m.shape[1]\n",
    "\t\tsignals_CR = (re_m==m).sum() # correct reconstruct entries of signals\n",
    "\t\tratio_m_CR = (signals_CR / total_m_entries).item()\n",
    "\t\treturn ratio_m_CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "700e31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████| 1000/1000 [04:24<00:00,  3.79it/s, epoch_loss=2.92e+02]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 1000\n",
    "pyro.clear_param_store()\n",
    "m_SigBeta = model_signals_only_fixedBeta(\n",
    "    num_signals = generator.num_signals,\n",
    "    num_references = generator.num_references,\n",
    "    num_states = generator.num_states,\n",
    "    hidden = 32,\n",
    "    dropout = 0.2,\n",
    "    fixed_signalP = p)\n",
    "state_model.to(device)\n",
    "optimizer = pyro.optim.Adam({\"lr\": learning_rate})\n",
    "svi = SVI(m_SigBeta.model, m_SigBeta.guide, optimizer, loss=TraceMeanField_ELBO())\n",
    "num_batches = int(math.ceil(m.shape[0] / batch_size))\n",
    "\n",
    "bar = trange(num_epochs)\n",
    "for epoch in bar:\n",
    "    running_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        batch_m = m[i * batch_size:(i+1) * batch_size, :]\n",
    "        batch_r = r[i * batch_size:(i+1) * batch_size, :, :]\n",
    "        loss = svi.step(batch_m) # p from the generated data\n",
    "        running_loss += loss / batch_m.size(0)\n",
    "        \n",
    "    bar.set_postfix(epoch_loss='{:.2e}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8ab55cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 30])\n",
      "tensor([[1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.]])\n",
      "tensor([[1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.]])\n",
      "tensor(8111)\n",
      "tensor(284327)\n"
     ]
    }
   ],
   "source": [
    "# new_m = torch.tensor([[1,0,0], [0,1,0], [0,0,1]]).float()\n",
    "# logpi_loc, logpi_scale = state_model.encoder(new_m)\n",
    "# print(logpi_loc.shape)\n",
    "# print(logpi_loc)\n",
    "# print(F.softmax(logpi_loc, 1))\n",
    "# x = logpi_loc[0,:] * 1.0e5\n",
    "# print(logpi_loc[0,:])\n",
    "# print(x)\n",
    "# print(F.softmax(x, 0))\n",
    "re_m = m_SigBeta.generate_reconstructed_data(m)\n",
    "print(re_m.shape)\n",
    "print(m)\n",
    "print(re_m)\n",
    "print(((m==re_m).all(dim=1)).sum())\n",
    "print((m==re_m).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d431f617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>max_state_x</th>\n",
       "      <th>0_y</th>\n",
       "      <th>1_y</th>\n",
       "      <th>2_y</th>\n",
       "      <th>max_state_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.899916</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.050021</td>\n",
       "      <td>0</td>\n",
       "      <td>0.834900</td>\n",
       "      <td>0.131686</td>\n",
       "      <td>0.033414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046013</td>\n",
       "      <td>0.046014</td>\n",
       "      <td>0.907973</td>\n",
       "      <td>2</td>\n",
       "      <td>0.077855</td>\n",
       "      <td>0.347474</td>\n",
       "      <td>0.574671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037355</td>\n",
       "      <td>0.925289</td>\n",
       "      <td>0.037355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072862</td>\n",
       "      <td>0.806724</td>\n",
       "      <td>0.120414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048280</td>\n",
       "      <td>0.048280</td>\n",
       "      <td>0.903441</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215188</td>\n",
       "      <td>0.214566</td>\n",
       "      <td>0.570246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037980</td>\n",
       "      <td>0.924041</td>\n",
       "      <td>0.037980</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219506</td>\n",
       "      <td>0.609871</td>\n",
       "      <td>0.170623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.060287</td>\n",
       "      <td>0.060280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695981</td>\n",
       "      <td>0.124986</td>\n",
       "      <td>0.179033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.053285</td>\n",
       "      <td>0.053285</td>\n",
       "      <td>0.893430</td>\n",
       "      <td>2</td>\n",
       "      <td>0.160222</td>\n",
       "      <td>0.126768</td>\n",
       "      <td>0.713009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.704853</td>\n",
       "      <td>0.178168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.425955</td>\n",
       "      <td>0.253359</td>\n",
       "      <td>0.320686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.052183</td>\n",
       "      <td>0.895634</td>\n",
       "      <td>0.052183</td>\n",
       "      <td>1</td>\n",
       "      <td>0.060238</td>\n",
       "      <td>0.722295</td>\n",
       "      <td>0.217468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0_x       1_x       2_x  max_state_x       0_y       1_y       2_y  \\\n",
       "0     0.899916  0.050063  0.050021            0  0.834900  0.131686  0.033414   \n",
       "1     0.046013  0.046014  0.907973            2  0.077855  0.347474  0.574671   \n",
       "2     0.037355  0.925289  0.037355            1  0.072862  0.806724  0.120414   \n",
       "3     0.048280  0.048280  0.903441            2  0.215188  0.214566  0.570246   \n",
       "4     0.037980  0.924041  0.037980            1  0.219506  0.609871  0.170623   \n",
       "...        ...       ...       ...          ...       ...       ...       ...   \n",
       "9995  0.879433  0.060287  0.060280            0  0.695981  0.124986  0.179033   \n",
       "9996  0.053285  0.053285  0.893430            2  0.160222  0.126768  0.713009   \n",
       "9997  0.333333  0.333333  0.333333            0  0.116979  0.704853  0.178168   \n",
       "9998  0.333334  0.333333  0.333334            0  0.425955  0.253359  0.320686   \n",
       "9999  0.052183  0.895634  0.052183            1  0.060238  0.722295  0.217468   \n",
       "\n",
       "      max_state_y  \n",
       "0               0  \n",
       "1               2  \n",
       "2               1  \n",
       "3               2  \n",
       "4               1  \n",
       "...           ...  \n",
       "9995            0  \n",
       "9996            2  \n",
       "9997            1  \n",
       "9998            0  \n",
       "9999            1  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cpi = m_SigBeta.predict_state_assignment(m)\n",
    "t = pd.DataFrame(Cpi.detach().numpy())\n",
    "t['max_state'] = t.idxmax(axis =1)\n",
    "t = t.merge(collapsed_theta, left_index = True, right_index = True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1cd17209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6960"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t['max_state_x'] == t['max_state_y']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='/Users/vuh6/Desktop/mount_ros/source/hector_transferChromState/simulation_model_design/experiments/strict_genData'\n",
    "import glob\n",
    "import pandas as pd\n",
    "fn_list = glob.glob(folder+ '/*.txt')\n",
    "df_list = list(map(lambda x: pd.read_csv(x, header = 0, index_col = None, sep = '\\t'), fn_list))\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafcd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = df.groupby(['model', 'num_states'])['ratio_m_CR'].mean().reset_index()\n",
    "import seaborn as sns\n",
    "sns.lineplot(data = t1, x = 'num_states', y = 'ratio_m_CR', hue = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a20463",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = df.groupby(['model', 'num_references'])['ratio_m_CR'].mean().reset_index()\n",
    "sns.lineplot(data = t2, x = 'num_references', y = 'ratio_m_CR', hue = 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378fab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f88d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
